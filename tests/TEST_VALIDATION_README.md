# AI/ML Test Output Validation

This directory contains test cases to validate that all AI/ML tests display the correct output in the UI with proper formatting and completeness.

## Overview

The test suite `test_ai_ml_output_validation.py` validates the enhanced output for:
- **Llama Model Tests** - Text generation and Llama-specific prompts
- **Embedding Tests** - Single and batch embeddings with similarity validation
- **OpenAI Tests** - Completion, embedding, and connection tests
- **Document Intelligence Tests** - Document analysis and structure extraction

## Running the Tests

### Prerequisites

```bash
# Install test dependencies
pip install pytest pytest-mock
```

### Run All Validation Tests

```bash
# From the project root
pytest tests/test_ai_ml_output_validation.py -v

# Run with coverage
pytest tests/test_ai_ml_output_validation.py -v --cov=app/tests --cov-report=html
```

### Run Specific Test Classes

```bash
# Test only Llama output validation
pytest tests/test_ai_ml_output_validation.py::TestLlamaTestOutput -v

# Test only Embedding output validation
pytest tests/test_ai_ml_output_validation.py::TestEmbeddingTestOutput -v

# Test only OpenAI output validation
pytest tests/test_ai_ml_output_validation.py::TestOpenAITestOutput -v

# Test only Document Intelligence output validation
pytest tests/test_ai_ml_output_validation.py::TestDocumentIntelligenceTestOutput -v

# Test output consistency across all tests
pytest tests/test_ai_ml_output_validation.py::TestOutputConsistency -v
```

## What These Tests Validate

### 1. Llama Model Test Output

âœ… **Text Generation Output:**
- Displays input prompt
- Shows model response (preview)
- Includes duration metrics
- Uses consistent emoji indicators

âœ… **Llama-Style Prompt Output:**
- Shows Llama-specific questions
- Displays model responses mentioning "Llama"
- Includes timing information

**Example Expected Output:**
```
ğŸ’¬ Running text generation test...
âœ… Text generation test passed
   ğŸ“ Input: Hello! Can you introduce yourself briefly?
   ğŸ’¬ Output: I am a helpful AI assistant designed to...
   â±ï¸  Duration: 2.27s
```

### 2. Embedding Test Output

âœ… **Single Embedding Output:**
- Shows input text
- Displays embedding dimensions (e.g., 1536)
- Shows value range (min/max)
- Includes token usage
- Displays processing time

âœ… **Batch Embedding Output:**
- Shows batch size
- Displays average time per embedding
- Shows total processing time

âœ… **Summary Section:**
- Model name
- Embedding dimensions
- Processing times
- Uses separator lines (60 '=' characters)

**Example Expected Output:**
```
ğŸ”¢ Running single embedding test...
âœ… Single embedding test passed
   ğŸ“ Input: 'This is a test sentence for embedding generation.'
   ğŸ“ Embedding Dimension: 1536
   â±ï¸  Processing Time: 0.342s
   ğŸ“Š Value Range: [-0.015234, 0.023456]
   ğŸ¯ Tokens Used: 12
```

### 3. OpenAI Test Output

âœ… **Connection Test:**
- Shows number of models found
- Displays response time

âœ… **Completion Test:**
- Shows model name
- Displays input prompt
- Shows model output
- Includes validation status (e.g., "contains 4")
- Token breakdown (prompt + completion + total)
- Duration

âœ… **Embedding Test:**
- Model name
- Input text
- Embedding dimensions
- Sample values (first 5)
- Token usage

âœ… **Summary Section:**
- Endpoint type (Azure vs OpenAI-compatible)
- Completion and embedding models

**Example Expected Output:**
```
ğŸ’¬ Running text completion test...
âœ… Text completion test passed
   ğŸ¤– Model: gpt-3.5-turbo
   ğŸ“ Input: What is 2+2? Answer with just the number.
   ğŸ’¬ Output: 4
   âœ“ Validation: Passed (contains 4)
   ğŸ¯ Tokens: 21 (20 prompt + 1 completion)
   â±ï¸  Duration: 1.23s
```

### 4. Document Intelligence Test Output

âœ… **Document Analysis:**
- Number of pages
- Table count
- Content length
- Processing time
- Content preview (first 100 chars)

âœ… **Custom File Analysis:**
- All above metrics plus:
- Paragraph count
- Key-value pairs extracted

âœ… **Summary Section:**
- Endpoint URL
- Model name
- Document structure statistics

**Example Expected Output:**
```
âœ… Document analysis test passed
   ğŸ“„ Pages: 2
   ğŸ“Š Tables: 1
   ğŸ“ Content Length: 523 characters
   â±ï¸  Processing Time: 4.23s
   ğŸ‘ï¸  Content Preview: Test Document This is a sample...
```

## Test Coverage

The validation tests cover:

### Output Format Tests (70% of tests)
- âœ… Correct emoji usage
- âœ… Proper indentation (3 spaces for details)
- âœ… Metric formatting (decimal places, units)
- âœ… Text truncation (preview lengths)

### Content Validation Tests (20% of tests)
- âœ… All expected fields present
- âœ… Values within expected ranges
- âœ… Proper data types

### Consistency Tests (10% of tests)
- âœ… Emoji indicators used consistently
- âœ… Duration format (X.XXs)
- âœ… Summary sections use 60-char separators
- âœ… Success/failure indicators

## Expected Test Results

When all tests pass, you should see:

```
tests/test_ai_ml_output_validation.py::TestLlamaTestOutput::test_llama_completion_output_format PASSED
tests/test_ai_ml_output_validation.py::TestLlamaTestOutput::test_llama_prompt_test_output_format PASSED
tests/test_ai_ml_output_validation.py::TestEmbeddingTestOutput::test_single_embedding_output_format PASSED
tests/test_ai_ml_output_validation.py::TestEmbeddingTestOutput::test_batch_embedding_output_format PASSED
tests/test_ai_ml_output_validation.py::TestEmbeddingTestOutput::test_embedding_summary_output PASSED
tests/test_ai_ml_output_validation.py::TestOpenAITestOutput::test_openai_connection_output PASSED
tests/test_ai_ml_output_validation.py::TestOpenAITestOutput::test_openai_completion_output_format PASSED
tests/test_ai_ml_output_validation.py::TestOpenAITestOutput::test_openai_embedding_output_format PASSED
tests/test_ai_ml_output_validation.py::TestOpenAITestOutput::test_openai_summary_output PASSED
tests/test_ai_ml_output_validation.py::TestDocumentIntelligenceTestOutput::test_document_analysis_output_format PASSED
tests/test_ai_ml_output_validation.py::TestDocumentIntelligenceTestOutput::test_document_intelligence_summary_output PASSED
tests/test_ai_ml_output_validation.py::TestDocumentIntelligenceTestOutput::test_custom_file_analysis_output PASSED
tests/test_ai_ml_output_validation.py::TestOutputConsistency::test_all_tests_use_emoji_indicators PASSED
tests/test_ai_ml_output_validation.py::TestOutputConsistency::test_all_tests_have_summary_sections PASSED
tests/test_ai_ml_output_validation.py::TestOutputConsistency::test_duration_formatting_consistency PASSED

============================== 15 passed in X.XXs ===============================
```

## Troubleshooting

### Common Issues

**Issue: Import errors**
```bash
# Solution: Ensure you're running from project root
cd /Users/davidpacold/Documents/Github/airia-test-pod
pytest tests/test_ai_ml_output_validation.py -v
```

**Issue: Mock not working**
```bash
# Solution: Install pytest-mock
pip install pytest-mock
```

**Issue: Tests fail due to output format changes**
- Check if the actual test files have been modified
- Update the validation tests to match new format
- Ensure emoji indicators are still consistent

## Adding New Tests

To add validation for a new AI/ML test:

1. **Create a new test class:**
```python
class TestNewAITestOutput:
    """Test cases for new AI test output validation"""
```

2. **Add output format test:**
```python
@patch('app.tests.new_test.SomeClient')
def test_new_ai_output_format(self, mock_client):
    # Setup mocks
    # Capture stdout
    # Run test
    # Validate output contains expected elements
```

3. **Add to consistency tests if needed:**
```python
def test_new_ai_uses_consistent_emojis(self):
    # Validate emoji usage
```

## Output Standards

All AI/ML tests should follow these standards:

### Emoji Indicators
- ğŸ”— Connection/API tests
- ğŸ’¬ Text generation/completion
- ğŸ”¢ Embeddings
- ğŸ“ Input data
- ğŸ’¬ Output/response
- â±ï¸  Duration/time
- ğŸ¯ Tokens
- ğŸ“Š Metrics/statistics
- âœ… Success
- âŒ Failure
- ğŸ‰ Summary/completion
- ğŸ“„ Documents/pages
- ğŸ¤– Model name

### Formatting Rules
1. **Indentation:** 3 spaces for detail lines
2. **Duration:** Always format as `X.XXs` (2 decimal places + 's')
3. **Summary:** Use `"=" * 60` separator lines
4. **Preview:** Truncate long text with `...`
   - Prompts: 80 chars max
   - Responses: 100 chars max
   - Content: 100 chars max

### Required Sections
1. **Test announcement:** e.g., "ğŸ’¬ Running text completion test..."
2. **Success/failure:** e.g., "âœ… Text completion test passed"
3. **Details:** Model, input, output, metrics
4. **Summary (if all pass):** Final statistics with separators

## Continuous Integration

These tests can be integrated into CI/CD:

```yaml
# .github/workflows/test-ai-ml-output.yml
name: AI/ML Output Validation

on: [push, pull_request]

jobs:
  validate-output:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'
      - name: Install dependencies
        run: |
          pip install pytest pytest-mock
      - name: Run output validation tests
        run: |
          pytest tests/test_ai_ml_output_validation.py -v
```

## Contributing

When modifying AI/ML test output:

1. Update the corresponding test in `test_ai_ml_output_validation.py`
2. Run validation tests to ensure format consistency
3. Document any new emoji indicators or formatting rules
4. Ensure backward compatibility where possible

## License

Same as parent project.
